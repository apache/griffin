{
  "name": "accu_streaming",

  "process.type": "streaming",

  "data.sources": [
    {
      "name": "source",
      "baseline": true,
      "connectors": [
        {
          "type": "kafka",
          "version": "0.8",
          "config": {
            "kafka.config": {
              "bootstrap.servers": "10.149.247.156:9092",
              "group.id": "group1",
              "auto.offset.reset": "smallest",
              "auto.commit.enable": "false"
            },
            "topics": "sss",
            "key.type": "java.lang.String",
            "value.type": "java.lang.String"
          },
          "pre.proc": [
            {
              "dsl.type": "df-opr",
              "name": "${s1}",
              "rule": "from_json",
              "details": {
                "df.name": "${this}"
              }
            },
            {
              "dsl.type": "spark-sql",
              "name": "${this}",
              "rule": "select name, age from ${s1}"
            }
          ]
        }
      ],
      "cache": {
        "file.path": "hdfs://localhost/griffin/streaming/dump/source",
        "info.path": "source",
        "ready.time.interval": "10s",
        "ready.time.delay": "0",
        "time.range": ["-2m", "0"]
      }
    }, {
      "name": "target",
      "connectors": [
        {
          "type": "kafka",
          "version": "0.8",
          "config": {
            "kafka.config": {
              "bootstrap.servers": "10.149.247.156:9092",
              "group.id": "group1",
              "auto.offset.reset": "smallest",
              "auto.commit.enable": "false"
            },
            "topics": "ttt",
            "key.type": "java.lang.String",
            "value.type": "java.lang.String"
          },
          "pre.proc": [
            {
              "dsl.type": "df-opr",
              "name": "${t1}",
              "rule": "from_json",
              "details": {
                "df.name": "${this}"
              }
            },
            {
              "dsl.type": "spark-sql",
              "name": "${this}",
              "rule": "select name, age from ${t1}"
            }
          ]
        }
      ],
      "cache": {
        "file.path": "hdfs://localhost/griffin/streaming/dump/target",
        "info.path": "target",
        "ready.time.interval": "10s",
        "ready.time.delay": "0",
        "time.range": ["-2m", "0"]
      }
    }
  ],

  "evaluate.rule": {
    "rules": [
      {
        "dsl.type": "spark-sql",
        "name": "missRecords",
        "cache": true,
        "rule": "SELECT source.* FROM source LEFT JOIN target ON coalesce(source.name, '') = coalesce(target.name, '') AND coalesce(source.age, '') = coalesce(target.age, '') WHERE (NOT (source.name IS NULL AND source.age IS NULL)) AND (target.name IS NULL AND target.age IS NULL)"
      },
      {
        "dsl.type": "spark-sql",
        "name": "miss_count",
        "rule": "SELECT `__tmst`, count(*) as miss FROM `missRecords` GROUP BY `__tmst`"
      },
      {
        "dsl.type": "spark-sql",
        "name": "total_count",
        "rule": "SELECT `__tmst`, count(*) as total FROM source GROUP BY `__tmst`"
      },
      {
        "dsl.type": "spark-sql",
        "name": "accu",
        "rule": "SELECT `total_count`.`__tmst` AS `__tmst`, `total_count`.`total` AS `total`, coalesce(`miss_count`.`miss`, 0) AS `miss` FROM `total_count` FULL JOIN `miss_count` ON `total_count`.`__tmst` = `miss_count`.`__tmst`"
      },
      {
        "dsl.type": "df-opr",
        "name": "metric_accu",
        "rule": "accuracy",
        "details": {
          "df.name": "accu",
          "miss": "miss",
          "total": "total",
          "matched": "matched"
        },
        "metric": {
          "name": "accuracy"
        }
      },
      {
        "dsl.type": "spark-sql",
        "name": "accu_miss_records",
        "rule": "SELECT `__tmst`, `__empty` FROM `metric_accu` WHERE `__record`",
        "record": {
          "name": "missRecords",
          "data.source.cache": "source",
          "origin.DF": "missRecords"
        }
      }
    ]
  }
}